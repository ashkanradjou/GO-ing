{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CLkztlkCiUVM",
        "YaoP5hjqicSs",
        "WOIOr2sk9HLJ"
      ],
      "authorship_tag": "ABX9TyOCXkcWJ9ogiToA2Y50n7av",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashkanradjou/GO-ing/blob/main/Worker_Pool_go.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initial setup"
      ],
      "metadata": {
        "id": "CLkztlkCiUVM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdBik8t6HNs",
        "outputId": "5fe4ff42-e9b4-4860-a158-f636c842b94e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-27 09:08:28--  https://dl.google.com/go/go1.19.6.linux-amd64.tar.gz\n",
            "Resolving dl.google.com (dl.google.com)... 173.194.217.91, 173.194.217.93, 173.194.217.190, ...\n",
            "Connecting to dl.google.com (dl.google.com)|173.194.217.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149006448 (142M) [application/x-gzip]\n",
            "Saving to: ‘go1.19.6.linux-amd64.tar.gz’\n",
            "\n",
            "go1.19.6.linux-amd6 100%[===================>] 142.10M  31.2MB/s    in 4.5s    \n",
            "\n",
            "2025-10-27 09:08:33 (31.6 MB/s) - ‘go1.19.6.linux-amd64.tar.gz’ saved [149006448/149006448]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#download binaries for go\n",
        "!wget https://dl.google.com/go/go1.19.6.linux-amd64.tar.gz\n",
        "\n",
        "#extract binaries from tarball and place in /usr/local directory\n",
        "!sudo tar -C /usr/local -xzf go1.19.6.linux-amd64.tar.gz\n",
        "\n",
        "#remove tarball\n",
        "!rm go1.19.6.linux-amd64.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#add the go executable to path\n",
        "os.environ['PATH'] += ':/usr/local/go/bin'"
      ],
      "metadata": {
        "id": "pTJYB0197M4A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!go version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSct8pg_7Vsq",
        "outputId": "bc724790-235d-4ef7-ee62-603b96c40a73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go version go1.19.6 linux/amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code"
      ],
      "metadata": {
        "id": "YaoP5hjqicSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.go\n",
        "\n",
        "package main\n",
        "\n",
        "import (\n",
        "\t\"context\"\n",
        "\t\"errors\"\n",
        "\t\"fmt\"\n",
        "\t\"math/rand\"\n",
        "\t\"net/http\"\n",
        "\t\"sync\"\n",
        "\t\"time\"\n",
        ")\n",
        "\n",
        "/*\n",
        "Part A: Worker Pool (Image thumbnailer)\n",
        "- input: paths (string) -> buffered channel (backpressure)\n",
        "- workers: n goroutines that create thumbnails (simulation)\n",
        "- output: thumbnails -> buffered channel\n",
        "- clean shutdown: when the producer closes the input channel, the workers finish cleanly and then the output is closed\n",
        "*/\n",
        "\n",
        "// thumbnailResult is the output schema of each worker\n",
        "type thumbnailResult struct {\n",
        "\tPath     string\n",
        "\tThumb    string\n",
        "\tDuration time.Duration\n",
        "\tErr      error\n",
        "}\n",
        "\n",
        "func workerThumbnail(ctx context.Context, id int, in <-chan string, out chan<- thumbnailResult, wg *sync.WaitGroup) {\n",
        "\tdefer wg.Done()\n",
        "\tfor {\n",
        "\t\tselect {\n",
        "\t\tcase <-ctx.Done():\n",
        "\t\t\t//We exit when the entire context is canceled.\n",
        "\t\t\tfmt.Printf(\"worker-%d: context canceled, exiting\\n\", id)\n",
        "\t\t\treturn\n",
        "\t\tcase path, ok := <-in:\n",
        "\t\t\tif !ok {\n",
        "\t\t\t\t// Input channel closed => job done\n",
        "\t\t\t\tfmt.Printf(\"worker-%d: input channel closed, exiting\\n\", id)\n",
        "\t\t\t\treturn\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\t// Thumbnail processing simulation (may have I/O)\n",
        "\t\t\tstart := time.Now()\n",
        "\t\t\t// simulate variable work time\n",
        "\t\t\ttime.Sleep(time.Duration(100+rand.Intn(300)) * time.Millisecond)\n",
        "\n",
        "\t\t\t// Error simulation for some paths\n",
        "\t\t\tvar err error\n",
        "\t\t\tif rand.Float32() < 0.05 {\n",
        "\t\t\t\terr = errors.New(\"failed to create thumbnail (simulated)\")\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\tres := thumbnailResult{\n",
        "\t\t\t\tPath:     path,\n",
        "\t\t\t\tThumb:    fmt.Sprintf(\"%s.thumb.jpg\", path),\n",
        "\t\t\t\tDuration: time.Since(start),\n",
        "\t\t\t\tErr:      err,\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\tselect {\n",
        "\t\t\tcase <-ctx.Done():\n",
        "\t\t\t\treturn\n",
        "\t\t\tcase out <- res:\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "/*\n",
        "Part B: Rate-limited fetcher + retry with backoff\n",
        "- A simple token-bucket with a ticker that fills tokens (burst capability)\n",
        "- retryWithBackoff functions that respect context and can choose between fixed or exponential backoff\n",
        "*/\n",
        "\n",
        "func newTokenBucket(ctx context.Context, ratePerSec int, burst int) <-chan struct{} {\n",
        "\t// The channel where the token is placed\n",
        "\ttokens := make(chan struct{}, burst)\n",
        "\n",
        "\tfor i := 0; i < burst; i++ {\n",
        "\t\ttokens <- struct{}{}\n",
        "\t}\n",
        "\n",
        "\tticker := time.NewTicker(time.Second / time.Duration(ratePerSec))\n",
        "\tgo func() {\n",
        "\t\tdefer ticker.Stop()\n",
        "\t\tfor {\n",
        "\t\t\tselect {\n",
        "\t\t\tcase <-ctx.Done():\n",
        "\t\t\t\tclose(tokens)\n",
        "\t\t\t\treturn\n",
        "\t\t\tcase <-ticker.C:\n",
        "\t\t\t\t// Try adding a token (don't add if buffer is full)\n",
        "\t\t\t\tselect {\n",
        "\t\t\t\tcase tokens <- struct{}{}:\n",
        "\t\t\t\tdefault:\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}()\n",
        "\n",
        "\treturn tokens\n",
        "}\n",
        "\n",
        "// If ctx.Done() is triggered, it returns immediately.\n",
        "func doWithRetry(ctx context.Context, op func() error, maxRetries int, initialDelay time.Duration, multiplier float64, jitter bool) error {\n",
        "\tdelay := initialDelay\n",
        "\tfor attempt := 0; attempt <= maxRetries; attempt++ {\n",
        "\t\t// Check whether the context has been canceled before executing the attempt.\n",
        "\t\tselect {\n",
        "\t\tcase <-ctx.Done():\n",
        "\t\t\treturn ctx.Err()\n",
        "\t\tdefault:\n",
        "\t\t}\n",
        "\n",
        "\t\terr := op()\n",
        "\t\tif err == nil {\n",
        "\t\t\treturn nil\n",
        "\t\t}\n",
        "\n",
        "\t\t// If it was the last attempt, return an error.\n",
        "\t\tif attempt == maxRetries {\n",
        "\t\t\treturn err\n",
        "\t\t}\n",
        "\n",
        "\t\t//Preparing the next delay\n",
        "\t\tsleep := delay\n",
        "\t\tif jitter {\n",
        "\t\t\tj := 0.5 + rand.Float64()\n",
        "\t\t\tsleep = time.Duration(float64(sleep) * j)\n",
        "\t\t}\n",
        "\n",
        "\t\tselect {\n",
        "\t\tcase <-ctx.Done():\n",
        "\t\t\treturn ctx.Err()\n",
        "\t\tcase <-time.After(sleep):\n",
        "\t\t}\n",
        "\n",
        "\t\tdelay = time.Duration(float64(delay) * multiplier)\n",
        "\t\tif delay > 10*time.Second {\n",
        "\t\t\tdelay = 10 * time.Second\n",
        "\t\t}\n",
        "\t}\n",
        "\treturn errors.New(\"unreachable\")\n",
        "}\n",
        "\n",
        "// Rate Limited Fetcher: Fetching URLs from in-chan, sends each request to the token bucket with respect.\n",
        "// After fetch, it sends the result to out (in this example it is only simulated)\n",
        "type fetchResult struct {\n",
        "\tURL      string\n",
        "\tBodySize int\n",
        "\tErr      error\n",
        "}\n",
        "\n",
        "func rateLimitedFetcher(ctx context.Context, id int, in <-chan string, out chan<- fetchResult, tokens <-chan struct{}, fetchTimeout time.Duration, wg *sync.WaitGroup) {\n",
        "\tdefer wg.Done()\n",
        "\tclient := &http.Client{\n",
        "\t\tTimeout: fetchTimeout,\n",
        "\t}\n",
        "\tfor {\n",
        "\t\tselect {\n",
        "\t\tcase <-ctx.Done():\n",
        "\t\t\tfmt.Printf(\"fetcher-%d: context canceled, exiting\\n\", id)\n",
        "\t\t\treturn\n",
        "\t\tcase url, ok := <-in:\n",
        "\t\t\tif !ok {\n",
        "\t\t\t\tfmt.Printf(\"fetcher-%d: input closed, exiting\\n\", id)\n",
        "\t\t\t\treturn\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\t// Receive tokens (rate limiting). If the tokens channel is closed, respect and exit.\n",
        "\t\t\tselect {\n",
        "\t\t\tcase <-ctx.Done():\n",
        "\t\t\t\treturn\n",
        "\t\t\tcase _, ok := <-tokens:\n",
        "\t\t\t\tif !ok {\n",
        "\t\t\t\t\t// token bucket closed => stop\n",
        "\t\t\t\t\tfmt.Printf(\"fetcher-%d: tokens closed, exiting\\n\", id)\n",
        "\t\t\t\t\treturn\n",
        "\t\t\t\t}\n",
        "\t\t\t\t// got token -> proceed\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\t// define op to fetch (simple GET)\n",
        "\t\t\top := func() error {\n",
        "\t\t\t\treq, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n",
        "\t\t\t\tif err != nil {\n",
        "\t\t\t\t\treturn err\n",
        "\t\t\t\t}\n",
        "\t\t\t\t// in demo we don't read body fully to keep it fast\n",
        "\t\t\t\tresp, err := client.Do(req)\n",
        "\t\t\t\tif err != nil {\n",
        "\t\t\t\t\treturn err\n",
        "\t\t\t\t}\n",
        "\t\t\t\tdefer resp.Body.Close()\n",
        "\t\t\t\t// simulate reading body size\n",
        "\t\t\t\tn := 100 + rand.Intn(2000)\n",
        "\t\t\t\t// treat non-2xx as error\n",
        "\t\t\t\tif resp.StatusCode < 200 || resp.StatusCode >= 300 {\n",
        "\t\t\t\t\treturn fmt.Errorf(\"bad status %d\", resp.StatusCode)\n",
        "\t\t\t\t}\n",
        "\t\t\t\t// simulate some processing time\n",
        "\t\t\t\ttime.Sleep(time.Duration(50+rand.Intn(200)) * time.Millisecond)\n",
        "\t\t\t\toutRes := fetchResult{URL: url, BodySize: n, Err: nil}\n",
        "\t\t\t\t// send result with respect to ctx\n",
        "\t\t\t\tselect {\n",
        "\t\t\t\tcase <-ctx.Done():\n",
        "\t\t\t\t\treturn ctx.Err()\n",
        "\t\t\t\tcase out <- outRes:\n",
        "\t\t\t\t\treturn nil\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\t//Run op with retries and exponential backoff (example: max 3 retries)\n",
        "\t\t\terr := doWithRetry(ctx, op, 3, 200*time.Millisecond, 2.0, true)\n",
        "\t\t\tif err != nil {\n",
        "\t\t\t\t// Sending errors to output\n",
        "\t\t\t\tselect {\n",
        "\t\t\t\tcase <-ctx.Done():\n",
        "\t\t\t\tcase out <- fetchResult{URL: url, Err: err}:\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "/*\n",
        "main: An example of using both systems:\n",
        "- Send video/image path to inputThumbnailCh (buffered -> backpressure)\n",
        "- n number of workers\n",
        "- Read and print the thumbnails output\n",
        "- Also an example of a rate-limited fetcher that grabs URLs, limits them with tokens, and sends the results\n",
        "*/\n",
        "\n",
        "func main() {\n",
        "\trand.Seed(time.Now().UnixNano())\n",
        "\n",
        "\trootCtx, cancelRoot := context.WithTimeout(context.Background(), 10*time.Second)\n",
        "\tdefer cancelRoot()\n",
        "\n",
        "\t// ------------ Worker Pool: Thumbnailer ------------\n",
        "\tinThumb := make(chan string, 5)\n",
        "\toutThumb := make(chan thumbnailResult)\n",
        "\tvar wgThumb sync.WaitGroup\n",
        "\tnumThumbWorkers := 4\n",
        "\n",
        "\t// start workers\n",
        "\tfor i := 0; i < numThumbWorkers; i++ {\n",
        "\t\twgThumb.Add(1)\n",
        "\t\tgo workerThumbnail(rootCtx, i+1, inThumb, outThumb, &wgThumb)\n",
        "\t}\n",
        "\n",
        "\t// producer: Simulate sending file paths\n",
        "\tgo func() {\n",
        "\t\tpaths := []string{\n",
        "\t\t\t\"img1.jpg\", \"img2.jpg\", \"img3.jpg\", \"img4.jpg\", \"img5.jpg\",\n",
        "\t\t\t\"img6.jpg\", \"img7.jpg\", \"img8.jpg\", \"img9.jpg\", \"img10.jpg\",\n",
        "\t\t}\n",
        "\t\tfor _, p := range paths {\n",
        "\t\t\tselect {\n",
        "\t\t\tcase <-rootCtx.Done():\n",
        "\t\t\t\tfmt.Println(\"producer thumbnails: context canceled, stop producing\")\n",
        "\t\t\t\tclose(inThumb)\n",
        "\t\t\t\treturn\n",
        "\t\t\tcase inThumb <- p: // If the buffer is full, this send will be blocked and backpressure will occur.\n",
        "\t\t\t\tfmt.Println(\"producer thumbnails: enqueued\", p)\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\t// When finished, we close the input channel so that workers know the work is done.\n",
        "\t\tclose(inThumb)\n",
        "\t\tfmt.Println(\"producer thumbnails: closed input channel\")\n",
        "\t}()\n",
        "\n",
        "\t// consumer of thumbnails — close outThumb after workers are finished\n",
        "\tgo func() {\n",
        "\t\twgThumb.Wait()\n",
        "\t\tclose(outThumb)\n",
        "\t\tfmt.Println(\"thumbnail consumer: closed outThumb after workers finished\")\n",
        "\t}()\n",
        "\n",
        "\t// reader for outThumb\n",
        "\tgo func() {\n",
        "\t\tfor tr := range outThumb {\n",
        "\t\t\tif tr.Err != nil {\n",
        "\t\t\t\tfmt.Printf(\"[thumbnail ERROR] %s -> %v (took %s)\\n\", tr.Path, tr.Err, tr.Duration)\n",
        "\t\t\t} else {\n",
        "\t\t\t\tfmt.Printf(\"[thumbnail READY] %s -> %s (took %s)\\n\", tr.Path, tr.Thumb, tr.Duration)\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}()\n",
        "\n",
        "\t// ------------ Rate-limited Fetcher ------------\n",
        "\t// In channel for URLs and out channel for results (buffered to allow some decoupling)\n",
        "\tinFetch := make(chan string, 10)\n",
        "\toutFetch := make(chan fetchResult, 10)\n",
        "\n",
        "\t// token bucket: rate 2 req/sec with burst 3\n",
        "\ttokenCtx, tokenCancel := context.WithCancel(rootCtx)\n",
        "\ttokens := newTokenBucket(tokenCtx, 2, 3)\n",
        "\n",
        "\tvar wgFetch sync.WaitGroup\n",
        "\tnumFetchers := 3\n",
        "\tfor i := 0; i < numFetchers; i++ {\n",
        "\t\twgFetch.Add(1)\n",
        "\t\tgo rateLimitedFetcher(rootCtx, i+1, inFetch, outFetch, tokens, 2*time.Second, &wgFetch)\n",
        "\t}\n",
        "\n",
        "\t// produce some URLs\n",
        "\tgo func() {\n",
        "\t\turls := []string{\n",
        "\t\t\t\"https://example.com/a\",\n",
        "\t\t\t\"https://example.com/b\",\n",
        "\t\t\t\"https://example.com/c\",\n",
        "\t\t\t\"https://example.com/d\",\n",
        "\t\t\t\"https://httpbin.org/status/500\", // simulate failure\n",
        "\t\t\t\"https://httpbin.org/status/403\", // simulate non-2xx\n",
        "\t\t}\n",
        "\t\tfor _, u := range urls {\n",
        "\t\t\tselect {\n",
        "\t\t\tcase <-rootCtx.Done():\n",
        "\t\t\t\tclose(inFetch)\n",
        "\t\t\t\treturn\n",
        "\t\t\tcase inFetch <- u:\n",
        "\t\t\t\tfmt.Println(\"enqueued url:\", u)\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\t// close input to signal fetchers to finish\n",
        "\t\tclose(inFetch)\n",
        "\t\tfmt.Println(\"closed inFetch\")\n",
        "\t}()\n",
        "\n",
        "\t// consumer for fetch results\n",
        "\tgo func() {\n",
        "\t\tfor fr := range outFetch {\n",
        "\t\t\tif fr.Err != nil {\n",
        "\t\t\t\tfmt.Printf(\"[fetch ERROR] %s -> %v\\n\", fr.URL, fr.Err)\n",
        "\t\t\t} else {\n",
        "\t\t\t\tfmt.Printf(\"[fetch OK] %s -> bytes=%d\\n\", fr.URL, fr.BodySize)\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\tfmt.Println(\"outFetch closed, fetch consumer exiting\")\n",
        "\t}()\n",
        "\n",
        "\t// wait for fetchers and then close outFetch\n",
        "\tgo func() {\n",
        "\t\twgFetch.Wait()\n",
        "\t\t// stop token supplier\n",
        "\t\ttokenCancel()\n",
        "\t\t// close outFetch to signal consumer\n",
        "\t\tclose(outFetch)\n",
        "\t}()\n",
        "\n",
        "\t// Waiting for everything to finish or a general timeout\n",
        "\t<-rootCtx.Done()\n",
        "\tfmt.Println(\"root context done — main exiting\")\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZUcfKXc7bET",
        "outputId": "505b6eb7-6c50-4a00-e2b7-1612f675793f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!go run main.go"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZpI3YIA7pMA",
        "outputId": "9d38ae1a-1f92-421f-84f9-ade93e9aa2a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "producer thumbnails: enqueued img1.jpg\n",
            "producer thumbnails: enqueued img2.jpg\n",
            "producer thumbnails: enqueued img3.jpg\n",
            "producer thumbnails: enqueued img4.jpg\n",
            "producer thumbnails: enqueued img5.jpg\n",
            "producer thumbnails: enqueued img6.jpg\n",
            "producer thumbnails: enqueued img7.jpg\n",
            "producer thumbnails: enqueued img8.jpg\n",
            "producer thumbnails: enqueued img9.jpg\n",
            "enqueued url: https://example.com/a\n",
            "enqueued url: https://example.com/b\n",
            "enqueued url: https://example.com/c\n",
            "enqueued url: https://example.com/d\n",
            "enqueued url: https://httpbin.org/status/500\n",
            "enqueued url: https://httpbin.org/status/403\n",
            "closed inFetch\n",
            "producer thumbnails: enqueued img10.jpg\n",
            "producer thumbnails: closed input channel\n",
            "[thumbnail READY] img4.jpg -> img4.jpg.thumb.jpg (took 209.677962ms)\n",
            "[thumbnail READY] img3.jpg -> img3.jpg.thumb.jpg (took 279.093469ms)\n",
            "[thumbnail READY] img1.jpg -> img1.jpg.thumb.jpg (took 312.083248ms)\n",
            "[thumbnail READY] img2.jpg -> img2.jpg.thumb.jpg (took 382.522967ms)\n",
            "[thumbnail READY] img5.jpg -> img5.jpg.thumb.jpg (took 383.453397ms)\n",
            "[thumbnail READY] img6.jpg -> img6.jpg.thumb.jpg (took 337.348381ms)\n",
            "worker-1: input channel closed, exiting\n",
            "[thumbnail READY] img7.jpg -> img7.jpg.thumb.jpg (took 388.627029ms)\n",
            "worker-3: input channel closed, exiting\n",
            "[thumbnail READY] img8.jpg -> img8.jpg.thumb.jpg (took 335.571244ms)\n",
            "worker-2: input channel closed, exiting\n",
            "[thumbnail READY] img9.jpg -> img9.jpg.thumb.jpg (took 146.202447ms)\n",
            "worker-4: input channel closed, exiting\n",
            "thumbnail consumer: closed outThumb after workers finished\n",
            "[thumbnail READY] img10.jpg -> img10.jpg.thumb.jpg (took 208.159135ms)\n",
            "[fetch ERROR] https://example.com/b -> Get \"https://example.com/b\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
            "[fetch ERROR] https://example.com/c -> Get \"https://example.com/c\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
            "[fetch ERROR] https://example.com/a -> Get \"https://example.com/a\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
            "fetcher-3: context canceled, exiting\n",
            "fetcher-2: context canceled, exiting\n",
            "[fetch ERROR] https://httpbin.org/status/403 -> context deadline exceeded\n",
            "root context done — main exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Readme"
      ],
      "metadata": {
        "id": "WOIOr2sk9HLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Go Worker Pool & Rate-Limited Fetcher Example\n",
        "\n",
        "This project demonstrates two distinct concepts implemented in Go:\n",
        "\n",
        "\n",
        "1.   **Worker Pool for Image Thumbnailing**\n",
        "\n",
        "2.   **Rate-Limited Fetcher with Retry Mechanism**\n",
        "\n",
        "Both are combined in a main application that processes tasks concurrently with proper error handling, backpressure, and rate limiting. The example uses Go’s concurrency model (goroutines and channels) to handle multiple tasks efficiently."
      ],
      "metadata": {
        "id": "obyKQrOI8dL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overview\n",
        "\n",
        "This project simulates a worker pool to generate image thumbnails and a rate-limited fetcher for HTTP requests, both controlled by context cancellation, error handling, and retries. Here's a summary of the two main parts:\n",
        "\n",
        "**Part A**: Worker Pool (Image Thumbnailing): Workers simulate the generation of image thumbnails concurrently. The worker pool uses buffered channels to control backpressure and ensures clean shutdown when the producer finishes processing.\n",
        "\n",
        "**Part B**: Rate-Limited Fetcher: A fetcher simulates HTTP requests to a list of URLs, controlling the request rate using a token bucket. It retries failed requests with exponential backoff and handles errors."
      ],
      "metadata": {
        "id": "d9cOSyOk9JE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Concepts Implemented\n",
        "\n",
        "**Part A: Worker Pool (Thumbnailer)**\n",
        "\n",
        "This part of the code simulates the process of creating image thumbnails. Here's how it works:\n",
        "\n",
        "\n",
        "*   Producer: A list of image paths is sent to the worker pool via a buffered input channel (inThumb).\n",
        "*   Worker Pool: n worker goroutines process the paths concurrently. Each worker simulates generating a thumbnail for an image.\n",
        "\n",
        "\n",
        "* Backpressure: The input channel is buffered, so if the buffer is full, the producer will block until there’s space.\n",
        "\n",
        "* Graceful Shutdown: The producer closes the input channel once all tasks are sent, signaling the workers to finish. Workers close the output channel after processing is done.\n",
        "\n",
        "Key features:\n",
        "\n",
        "* Context cancellation ensures that workers stop when required.\n",
        "\n",
        "* Errors in thumbnail creation are simulated and handled.\n",
        "\n",
        "**Part B: Rate-Limited Fetcher**\n",
        "\n",
        "In this part, an HTTP client simulates fetching URLs at a controlled rate using a token bucket algorithm. The fetcher respects rate limits and retries failed requests with exponential backoff.\n",
        "\n",
        "* Token Bucket: A token bucket is created with a specified rate (requests per second) and burst capacity. Each fetcher waits for a token before making an HTTP request.\n",
        "\n",
        "* Retry with Exponential Backoff: Failed fetch requests are retried with an increasing delay (with optional jitter).\n",
        "\n",
        "* Graceful Shutdown: Fetchers stop when the input channel is closed or the context is canceled.\n",
        "\n",
        "Key features:\n",
        "\n",
        "* Context cancellation allows early termination.\n",
        "\n",
        "* Retries failed requests with exponential backoff and optional jitter.\n",
        "\n",
        "* Fetch results are processed in a consumer goroutine."
      ],
      "metadata": {
        "id": "DnVrBIb09-BW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##How It Works\n",
        "\n",
        "**1.Thumbnail Worker Pool:**\n",
        "\n",
        "* A producer goroutine simulates paths of image files and sends them to a buffered channel (inThumb).\n",
        "\n",
        "* Multiple worker goroutines fetch paths from this channel, simulate thumbnail creation, and send results to an output channel (outThumb).\n",
        "\n",
        "* The input channel is closed after all paths are sent, signaling the workers to finish processing.\n",
        "\n",
        "* The results (thumbnails or errors) are printed by a consumer goroutine.\n",
        "\n",
        "**2.Rate-Limited Fetcher:**\n",
        "\n",
        "* A producer goroutine enqueues URLs to be fetched onto a buffered channel (inFetch).\n",
        "\n",
        "* A token bucket channel is used to limit the rate of HTTP requests.\n",
        "\n",
        "* Multiple fetcher goroutines wait for tokens before performing HTTP requests.\n",
        "\n",
        "* The fetchers respect context cancellation and retry failed requests with exponential backoff."
      ],
      "metadata": {
        "id": "R6CH_Jm3AVWL"
      }
    }
  ]
}